{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e374f5cc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- USER VARIABLES ---\n",
    "batch_size = 64\n",
    "test_batch_size = 1000\n",
    "epochs = 10  # Adjust for speed/accuracy\n",
    "learning_rate = 0.01\n",
    "log_steps = 100\n",
    "plot_results = True\n",
    "random_seed = 0\n",
    "\n",
    "# --- IMPORTS ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# --- DATA LOADING ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "train_set = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_set = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "# Split train_set into two disjoint sets for two clients\n",
    "total_train = len(train_set)\n",
    "client1_len = total_train // 2\n",
    "client2_len = total_train - client1_len\n",
    "client1_set, client2_set = random_split(train_set, [client1_len, client2_len], generator=torch.Generator().manual_seed(random_seed))\n",
    "client1_loader = torch.utils.data.DataLoader(client1_set, batch_size=batch_size, shuffle=True)\n",
    "client2_loader = torch.utils.data.DataLoader(client2_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "# --- FULL MODEL DEFINITION (LeNet5 variant) ---\n",
    "class LeNetSplit(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5), nn.ReLU(), nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, 5), nn.ReLU(), nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Linear(256, 120), nn.ReLU(),\n",
    "            nn.Linear(120, 84), nn.ReLU(),\n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.block3(x)\n",
    "        return x\n",
    "\n",
    "# --- SPLIT POINTS DEFINITION ---\n",
    "def get_split_models(split_point):\n",
    "    # Returns (client_model, server_model) for a given split_point (1-5)\n",
    "    class Client1(nn.Module):  # After block1\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.block1 = nn.Sequential(\n",
    "                nn.Conv2d(1, 6, 5), nn.ReLU(), nn.MaxPool2d(2, 2)\n",
    "            )\n",
    "        def forward(self, x): return self.block1(x)\n",
    "    class Server1(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.block2 = nn.Sequential(\n",
    "                nn.Conv2d(6, 16, 5), nn.ReLU(), nn.MaxPool2d(2, 2)\n",
    "            )\n",
    "            self.block3 = nn.Sequential(\n",
    "                nn.Linear(256, 120), nn.ReLU(),\n",
    "                nn.Linear(120, 84), nn.ReLU(),\n",
    "                nn.Linear(84, 10)\n",
    "            )\n",
    "        def forward(self, x):\n",
    "            x = self.block2(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.block3(x)\n",
    "            return x\n",
    "\n",
    "    class Client2(nn.Module):  # After block2[0] (2nd Conv)\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.block1 = nn.Sequential(\n",
    "                nn.Conv2d(1, 6, 5), nn.ReLU(), nn.MaxPool2d(2, 2)\n",
    "            )\n",
    "            self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        def forward(self, x):\n",
    "            x = self.block1(x)\n",
    "            x = self.conv2(x)\n",
    "            return x\n",
    "    class Server2(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.relu2 = nn.ReLU()\n",
    "            self.pool2 = nn.MaxPool2d(2, 2)\n",
    "            self.block3 = nn.Sequential(\n",
    "                nn.Linear(256, 120), nn.ReLU(),\n",
    "                nn.Linear(120, 84), nn.ReLU(),\n",
    "                nn.Linear(84, 10)\n",
    "            )\n",
    "        def forward(self, x):\n",
    "            x = self.relu2(x)\n",
    "            x = self.pool2(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.block3(x)\n",
    "            return x\n",
    "\n",
    "    class Client3(nn.Module):  # After block2 (2nd Conv+ReLU+Pool)\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.block1 = nn.Sequential(\n",
    "                nn.Conv2d(1, 6, 5), nn.ReLU(), nn.MaxPool2d(2, 2)\n",
    "            )\n",
    "            self.block2 = nn.Sequential(\n",
    "                nn.Conv2d(6, 16, 5), nn.ReLU(), nn.MaxPool2d(2, 2)\n",
    "            )\n",
    "        def forward(self, x):\n",
    "            x = self.block1(x)\n",
    "            x = self.block2(x)\n",
    "            return x\n",
    "    class Server3(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.block3 = nn.Sequential(\n",
    "                nn.Linear(256, 120), nn.ReLU(),\n",
    "                nn.Linear(120, 84), nn.ReLU(),\n",
    "                nn.Linear(84, 10)\n",
    "            )\n",
    "        def forward(self, x):\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.block3(x)\n",
    "            return x\n",
    "\n",
    "    class Client4(nn.Module):  # After block3[0] (first FC)\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.block1 = nn.Sequential(\n",
    "                nn.Conv2d(1, 6, 5), nn.ReLU(), nn.MaxPool2d(2, 2)\n",
    "            )\n",
    "            self.block2 = nn.Sequential(\n",
    "                nn.Conv2d(6, 16, 5), nn.ReLU(), nn.MaxPool2d(2, 2)\n",
    "            )\n",
    "            self.fc1 = nn.Linear(256, 120)\n",
    "        def forward(self, x):\n",
    "            x = self.block1(x)\n",
    "            x = self.block2(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.fc1(x)\n",
    "            return x\n",
    "    class Server4(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.relu1 = nn.ReLU()\n",
    "            self.fc2 = nn.Linear(120, 84)\n",
    "            self.relu2 = nn.ReLU()\n",
    "            self.fc3 = nn.Linear(84, 10)\n",
    "        def forward(self, x):\n",
    "            x = self.relu1(x)\n",
    "            x = self.fc2(x)\n",
    "            x = self.relu2(x)\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "    class Client5(nn.Module):  # After block3[2] (second FC)\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.block1 = nn.Sequential(\n",
    "                nn.Conv2d(1, 6, 5), nn.ReLU(), nn.MaxPool2d(2, 2)\n",
    "            )\n",
    "            self.block2 = nn.Sequential(\n",
    "                nn.Conv2d(6, 16, 5), nn.ReLU(), nn.MaxPool2d(2, 2)\n",
    "            )\n",
    "            self.fc1 = nn.Linear(256, 120)\n",
    "            self.relu1 = nn.ReLU()\n",
    "            self.fc2 = nn.Linear(120, 84)\n",
    "        def forward(self, x):\n",
    "            x = self.block1(x)\n",
    "            x = self.block2(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.fc1(x)\n",
    "            x = self.relu1(x)\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "    class Server5(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.relu2 = nn.ReLU()\n",
    "            self.fc3 = nn.Linear(84, 10)\n",
    "        def forward(self, x):\n",
    "            x = self.relu2(x)\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "    splits = [\n",
    "        (Client1, Server1),\n",
    "        (Client2, Server2),\n",
    "        (Client3, Server3),\n",
    "        (Client4, Server4),\n",
    "        (Client5, Server5)\n",
    "    ]\n",
    "    return splits[split_point-1][0](), splits[split_point-1][1]()\n",
    "\n",
    "split_names = [\n",
    "    \"After 1st Conv+ReLU+Pool\",\n",
    "    \"After 2nd Conv\",\n",
    "    \"After 2nd Conv+ReLU+Pool\",\n",
    "    \"After 1st FC\",\n",
    "    \"After 2nd FC\"\n",
    "]\n",
    "\n",
    "# --- TRAINING & EVALUATION LOOP FOR ALL SPLITS ---\n",
    "results = []\n",
    "for split_idx, split_name in enumerate(split_names):\n",
    "    print(f\"\\n=== Split {split_idx+1}: {split_name} ===\")\n",
    "    # Each client gets its own model and optimizer; server is shared\n",
    "    client1_model, server_model = get_split_models(split_idx+1)\n",
    "    client2_model, _ = get_split_models(split_idx+1)  # server_model is shared\n",
    "    client1_model, client2_model, server_model = client1_model.to(device), client2_model.to(device), server_model.to(device)\n",
    "    client1_optimizer = optim.SGD(client1_model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
    "    client2_optimizer = optim.SGD(client2_model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
    "    server_optimizer = optim.SGD(server_model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
    "    loss_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_losses, test_losses, test_accuracies = [], [], []\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        client1_model.train()\n",
    "        client2_model.train()\n",
    "        server_model.train()\n",
    "        running_loss = 0.0\n",
    "        # Alternate batches between clients\n",
    "        for (batch1, batch2) in zip(client1_loader, client2_loader):\n",
    "            for client_model, client_optimizer, (inputs, labels) in [\n",
    "                (client1_model, client1_optimizer, batch1),\n",
    "                (client2_model, client2_optimizer, batch2)\n",
    "            ]:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                client_optimizer.zero_grad()\n",
    "                server_optimizer.zero_grad()\n",
    "                # --- CLIENT FORWARD ---\n",
    "                split_activations = client_model(inputs)\n",
    "                split_activations = split_activations.detach().requires_grad_()\n",
    "                # --- SERVER FORWARD ---\n",
    "                outputs = server_model(split_activations)\n",
    "                loss = loss_criterion(outputs, labels)\n",
    "                # --- SERVER BACKWARD ---\n",
    "                loss.backward()\n",
    "                # --- SEND GRADIENT TO CLIENT, CLIENT BACKWARD ---\n",
    "                split_grads = split_activations.grad\n",
    "                split_activations.backward(split_grads)\n",
    "                # --- OPTIMIZER STEPS ---\n",
    "                client_optimizer.step()\n",
    "                server_optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "        avg_train_loss = running_loss / (len(client1_loader) + len(client2_loader))\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # --- EVALUATION (use client1 for test, or average both) ---\n",
    "        client1_model.eval()\n",
    "        server_model.eval()\n",
    "        test_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                split_activations = client1_model(inputs)\n",
    "                outputs = server_model(split_activations)\n",
    "                loss = loss_criterion(outputs, labels)\n",
    "                test_loss += loss.item() * labels.size(0)\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        avg_test_loss = test_loss / total\n",
    "        accuracy = correct / total\n",
    "        test_losses.append(avg_test_loss)\n",
    "        test_accuracies.append(accuracy)\n",
    "        print(f\"Epoch {epoch}: Test Loss: {avg_test_loss:.4f}, Test Accuracy: {accuracy*100:.2f}%\")\n",
    "\n",
    "    results.append({\n",
    "        \"split\": split_name,\n",
    "        \"train_losses\": train_losses,\n",
    "        \"test_losses\": test_losses,\n",
    "        \"test_accuracies\": test_accuracies\n",
    "    })\n",
    "\n",
    "# --- PLOTTING ---\n",
    "if plot_results:\n",
    "    epochs_range = range(1, epochs + 1)\n",
    "    plt.figure(figsize=(16,6))\n",
    "    for i, res in enumerate(results):\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(epochs_range, res[\"test_losses\"], label=res[\"split\"])\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Test Loss')\n",
    "        plt.title('Test Loss for Different Split Points')\n",
    "        plt.legend()\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(epochs_range, res[\"test_accuracies\"], label=res[\"split\"])\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Test Accuracy')\n",
    "        plt.title('Test Accuracy for Different Split Points')\n",
    "        plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- SAVE RESULTS TO CSV ---\n",
    "csv_rows = []\n",
    "for res in results:\n",
    "    split = res[\"split\"]\n",
    "    for epoch, (loss, acc) in enumerate(zip(res[\"test_losses\"], res[\"test_accuracies\"]), 1):\n",
    "        csv_rows.append({\n",
    "            \"split_name\": split,\n",
    "            \"epoch\": epoch,\n",
    "            \"test_loss\": loss,\n",
    "            \"test_accuracy\": acc\n",
    "        })\n",
    "df = pd.DataFrame(csv_rows)\n",
    "csv_filename = \"split_learning_results.csv\"\n",
    "df.to_csv(csv_filename, index=False)\n",
    "print(f\"Results saved to {csv_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
